{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45398736-7e89-4263-89c8-92153baff553",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "以下代码为 <a href=\"http://mng.bz/orYv\">《从零开始构建大型语言模型》</a> 一书的补充代码，作者为 <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>中文翻译和代码详细注释由Lux整理，Github下载地址：<a href=\"https://github.com/luxianyu\">https://github.com/luxianyu</a>\n",
    "    \n",
    "<br>Lux的Github上还有吴恩达深度学习Pytorch版学习笔记及中文详细注释的代码下载\n",
    "    \n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd524e-864c-4012-b0a2-ccfc56e80024",
   "metadata": {
    "id": "66dd524e-864c-4012-b0a2-ccfc56e80024"
   },
   "source": [
    "# 第5章：在无标签数据上进行预训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b989e9-da36-4159-b212-799184764dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.0\n",
      "numpy version: 2.1.3\n",
      "tiktoken version: 0.12.0\n",
      "torch version: 2.9.0+cpu\n",
      "tensorflow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# 导入函数 version，用于获取已安装包的版本号\n",
    "# -------------------------------------------------\n",
    "from importlib.metadata import version\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 定义要查询版本号的包列表\n",
    "# 包括：\n",
    "# - matplotlib: 绘图库\n",
    "# - numpy: 科学计算库\n",
    "# - tiktoken: OpenAI tokenizer 库\n",
    "# - torch: PyTorch 深度学习框架\n",
    "# - tensorflow: TensorFlow，用于加载 OpenAI 预训练权重\n",
    "# -------------------------------------------------\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "        \"tensorflow\"\n",
    "       ]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 遍历包列表\n",
    "# -------------------------------------------------\n",
    "for p in pkgs:\n",
    "    # 调用 version(p) 获取包 p 的版本号\n",
    "    # f-string 格式化输出包名和对应版本\n",
    "    print(f\"{p} version: {version(p)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3bdf9e-2ff0-4a57-abab-ede2d955a237",
   "metadata": {},
   "source": [
    "- 本章中，我们将实现训练循环和基本模型评估代码，以对大型语言模型（LLM）进行预训练  \n",
    "- 在本章末，我们还将从 OpenAI 加载公开可用的预训练权重到我们的模型中\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd27fcc-2886-47cb-b544-046c2c31f02a",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/01.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d214765-7a73-42d5-95e9-302154b29db9",
   "metadata": {},
   "source": [
    "- 本章涵盖的主题如下所示\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67711d4-8391-4fee-aeef-07ea53dd5841",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/02.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d824183-145c-4865-89e1-1f0d0a338f19",
   "metadata": {
    "id": "0d824183-145c-4865-89e1-1f0d0a338f19"
   },
   "source": [
    "## 5.1 生成式文本模型的评估\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3350f8c-5181-4f9b-a789-4523105e98f2",
   "metadata": {},
   "source": [
    "- 本节我们首先回顾如何使用上一章的代码来初始化一个 GPT 模型。  \n",
    "- 接着，我们将讨论用于评估大型语言模型（LLMs）的基本评价指标。  \n",
    "- 最后，在本节中，我们将把这些评价指标应用到训练集和验证集上。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd",
   "metadata": {
    "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd"
   },
   "source": [
    "### 5.1.1 使用 GPT 生成文本\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3415fd-9f4a-4548-908e-9dfa56edc9bc",
   "metadata": {},
   "source": [
    "- 我们使用上一章的代码初始化一个 GPT 模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86000d74-624a-48f0-86da-f41926cb9e04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86000d74-624a-48f0-86da-f41926cb9e04",
    "outputId": "ad482cfd-5a62-4f0d-e1e0-008d6457f512"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# 导入 PyTorch\n",
    "# -------------------------------------------------\n",
    "import torch\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 从前面章节的模块导入 GPTModel 类\n",
    "# -------------------------------------------------\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "# 如果本地没有 previous_chapters.py 文件，也可以从 PyPI 安装的 llms-from-scratch 包导入\n",
    "# 例如：\n",
    "# from llms_from_scratch.ch04 import GPTModel\n",
    "# 详细信息请参考：https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 定义 GPT 模型的配置信息\n",
    "# -------------------------------------------------\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # 词汇表大小（token 总数）\n",
    "    \"context_length\": 256,  # 最大上下文长度（原始 GPT-124M 模型为 1024，此处为了演示缩短为 256）\n",
    "    \"emb_dim\": 768,         # token embedding 的维度\n",
    "    \"n_heads\": 12,          # 多头注意力的头数\n",
    "    \"n_layers\": 12,         # Transformer 层数\n",
    "    \"drop_rate\": 0.1,       # dropout 概率\n",
    "    \"qkv_bias\": False       # Query/Key/Value 是否使用 bias\n",
    "}\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 设置随机种子，确保实验可复现\n",
    "# -------------------------------------------------\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 创建 GPT 模型实例\n",
    "# -------------------------------------------------\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 设置模型为评估模式（evaluation mode），\n",
    "# 关闭 dropout 等训练专用操作\n",
    "# -------------------------------------------------\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c6cf0f-7458-48a2-97fd-aa5068d65e8c",
   "metadata": {},
   "source": [
    "- 在上面的代码中，我们使用了 0.1 的 dropout，但如今训练 LLM 时通常并不会使用 dropout。  \n",
    "- 现代 LLM 在查询（query）、键（key）和值（value）矩阵对应的 `nn.Linear` 层中也不再使用偏置向量（bias vectors），这与早期的 GPT 模型不同，可以通过设置 `\"qkv_bias\": False` 来实现。  \n",
    "- 我们将上下文长度（`context_length`）缩减为 256 个 token，以降低训练模型所需的计算资源；而原始的 1.24 亿参数 GPT-2 模型使用的是 1024 个 token。  \n",
    "  - 这样做的目的是让更多读者能够在笔记本电脑上运行并理解代码示例。  \n",
    "  - 当然，你也可以将 `context_length` 增加到 1024（无需修改其他代码）。  \n",
    "  - 我们稍后还会从预训练权重中加载一个使用 1024 `context_length` 的模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f80895-be35-4bb5-81cb-f357ef7367fe",
   "metadata": {},
   "source": [
    "- 接下来，我们将使用上一章的 `generate_text_simple` 函数来生成文本。  \n",
    "- 此外，我们还定义了两个便捷函数：`text_to_token_ids` 和 `token_ids_to_text`，用于在 token 表示与文本表示之间进行转换，这两个函数将在本章中多次使用。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741881f3-cee0-49ad-b11d-b9df3b3ac234",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/03.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# 导入 tiktoken 用于 GPT-2 Tokenizer\n",
    "# -------------------------------------------------\n",
    "import tiktoken\n",
    "\n",
    "# 导入之前章节中实现的简单文本生成函数\n",
    "from previous_chapters import generate_text_simple\n",
    "# 或者，如果使用 PyPI 包：\n",
    "# from llms_from_scratch.ch04 import generate_text_simple\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 定义一个函数：将文本转为 token id 张量\n",
    "# -------------------------------------------------\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    \"\"\"\n",
    "    输入：\n",
    "        text: 待编码的字符串\n",
    "        tokenizer: tiktoken tokenizer 对象\n",
    "    输出：\n",
    "        encoded_tensor: [1, n_tokens] 的 LongTensor，添加了 batch 维度\n",
    "    \"\"\"\n",
    "    # encode 将文本转换为 token id 列表\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    # 转换为 tensor，并增加 batch 维度 (1, n_tokens)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 定义一个函数：将 token id 张量转回文本\n",
    "# -------------------------------------------------\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    \"\"\"\n",
    "    输入：\n",
    "        token_ids: [1, n_tokens] 或 [n_tokens] 的张量\n",
    "        tokenizer: tiktoken tokenizer 对象\n",
    "    输出：\n",
    "        text: 解码后的字符串\n",
    "    \"\"\"\n",
    "    # 压缩 batch 维度，[1, n_tokens] -> [n_tokens]\n",
    "    flat = token_ids.squeeze(0)\n",
    "    # 转为列表并解码\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 设置初始文本\n",
    "# -------------------------------------------------\n",
    "start_context = \"Every effort moves you\"\n",
    "\n",
    "# 创建 GPT-2 tokenizer 对象\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 使用简单生成函数生成新 token\n",
    "# -------------------------------------------------\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,  # GPT 模型对象\n",
    "    idx=text_to_token_ids(start_context, tokenizer),  # 将初始文本转换为 tensor\n",
    "    max_new_tokens=10,  # 新生成 token 数量\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]  # 使用的上下文长度\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 将生成的 token id 转换回文本\n",
    "# -------------------------------------------------\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3249b-b2a0-44c4-b589-ae4b403b8305",
   "metadata": {},
   "source": [
    "- 正如上面所看到的，模型生成的文本效果并不好，因为它尚未经过训练。  \n",
    "- 那么，我们该如何用数值的方式来衡量或捕捉“好文本”的概念，以便在训练过程中进行跟踪呢？  \n",
    "- 接下来的小节将介绍用于计算生成输出损失指标（loss metric）的方法，我们可以通过该指标来衡量训练的进展。  \n",
    "- 而在后续关于微调 LLM 的章节中，我们还将介绍更多用于评估模型质量的指标。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955f9e1a-7bf7-40d8-b1fa-eacabdee8d8e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98",
   "metadata": {
    "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98"
   },
   "source": [
    "### 5.1.2 Calculating the text generation loss: cross-entropy and perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ba8aa-fb03-4d25-957f-fe8778762440",
   "metadata": {},
   "source": [
    "- 假设我们有一个名为 `inputs` 的张量，其中包含两个训练样本（行）的 token ID。  \n",
    "- 与 `inputs` 对应的 `targets` 张量中，存放的是我们希望模型生成的目标 token ID。  \n",
    "- 请注意，`targets` 是由 `inputs` 向右平移一个位置得到的，这一点我们在第 2 章实现数据加载器（data loader）时已经解释过。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f",
    "outputId": "8d6fa0ff-7b37-4634-c3f0-2c050cbe81f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: torch.Size([2, 3])\n",
      "Targets shape: torch.Size([2, 3])\n",
      "\n",
      "Inputs:\n",
      " tensor([[16833,  3626,  6100],\n",
      "        [   40,  1107,   588]])\n",
      "\n",
      "Targets:\n",
      " tensor([[ 3626,  6100,   345],\n",
      "        [ 1107,   588, 11311]])\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# 定义示例输入序列\n",
    "# 每一行代表一个训练样本，每个数字是一个 token id\n",
    "# -------------------------------------------------\n",
    "inputs = torch.tensor([\n",
    "    [16833, 3626, 6100],   # 第 1 个样本对应的 token 序列 [\"every\", \"effort\", \"moves\"]\n",
    "    [40,    1107, 588]     # 第 2 个样本对应的 token 序列 [\"I\", \"really\", \"like\"]\n",
    "])\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 定义对应的目标序列（即下一个 token 的标签）\n",
    "# 每一行对应 inputs 的下一个 token 预测目标\n",
    "# -------------------------------------------------\n",
    "targets = torch.tensor([\n",
    "    [3626, 6100, 345],     # 第 1 个样本的目标 token id [\"effort\", \"moves\", \"you\"]\n",
    "    [1107, 588, 11311]     # 第 2 个样本的目标 token id [\"really\", \"like\", \"chocolate\"]\n",
    "])\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 输出输入与目标张量的形状及内容\n",
    "# -------------------------------------------------\n",
    "print(\"Inputs shape:\", inputs.shape)   # (batch_size=2, seq_len=3)\n",
    "print(\"Targets shape:\", targets.shape) # (batch_size=2, seq_len=3)\n",
    "print(\"\\nInputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc0645-ac2c-4973-9b40-6da40515bede",
   "metadata": {},
   "source": [
    "- 将 `inputs` 输入模型后，我们会得到对应的 logits 向量，对于这两个输入样本而言，每个样本包含 3 个 token。  \n",
    "- 每个 token 都对应一个 50,257 维的向量，这个维度大小与词汇表（vocabulary）的大小相同。  \n",
    "- 通过对 logits 张量应用 softmax 函数，我们可以将其转换为相同维度的张量，其中包含每个 token 的概率分数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b6ec51-6f8c-49bd-a349-95ba38b46fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 在推理模式下计算 logits（不计算梯度）\n",
    "# -------------------------------\n",
    "with torch.no_grad():  # 禁用梯度计算，提高效率，推理/生成时通常使用\n",
    "    logits = model(inputs)  \n",
    "    # logits 形状: [batch_size, seq_len, vocab_size]\n",
    "    # - batch_size: 样本数量，这里是 2\n",
    "    # - seq_len: 输入序列长度，这里是 3\n",
    "    # - vocab_size: 模型词汇表大小（例如 GPT-124M 是 50257）\n",
    "    # logits 中每个位置的向量表示该 token 在词表中每个词的得分（未归一化）\n",
    "    \n",
    "# -------------------------------\n",
    "# 将 logits 转换为概率\n",
    "# -------------------------------\n",
    "probas = torch.softmax(logits, dim=-1)  \n",
    "# softmax 说明：\n",
    "# - dim=-1 表示在最后一个维度上归一化，也就是对每个 token 的 vocab_size 个得分进行 softmax\n",
    "# - 输出 probas 形状与 logits 相同: [batch_size, seq_len, vocab_size]\n",
    "# - probas[i,j,k] 表示第 i 个样本，第 j 个 token 对应词表第 k 个词的预测概率\n",
    "\n",
    "# -------------------------------\n",
    "# 查看概率张量形状\n",
    "# -------------------------------\n",
    "print(probas.shape)  \n",
    "# 输出结果: torch.Size([2, 3, 50257])\n",
    "# - batch_size=2，seq_len=3，vocab_size=50257\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c36a382-b5e2-4de6-9e65-0b69b685013b",
   "metadata": {},
   "source": [
    "- 下图使用非常小的词汇表进行示例，概述了我们如何将概率分数转换回文本，这一点在上一章末尾已经讨论过：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384d86a9-0013-476c-bb6b-274fd5f20b29",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/04.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8480efd-d419-4954-9ecc-2876055334bd",
   "metadata": {},
   "source": [
    "- 正如上一章所讨论的，我们可以使用 `argmax` 函数将概率分数转换为预测的 token ID。  \n",
    "- 上述 softmax 函数为每个 token 生成了一个 50,257 维的向量；`argmax` 函数则返回该向量中概率最高的位置索引，即该 token 的预测 ID。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b84c9f-dd08-482e-b903-a86fe44e1144",
   "metadata": {},
   "source": [
    "- 由于我们有2个输入批次（batch），每个批次包含3个标记，因此我们得到一个 2×3 的预测标记 ID：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
    "outputId": "ed17da47-c3e7-4775-fd00-4ec5bcda3db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probas shape: torch.Size([2, 3, 50257])\n",
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 使用模型生成 logits，但不计算梯度\n",
    "# -------------------------------\n",
    "# torch.no_grad() 可以关闭梯度计算，节省内存和加速推理\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)  # logits 形状为 [batch_size, seq_len, vocab_size]\n",
    "\n",
    "# -------------------------------\n",
    "# 将 logits 转换为每个 token 的概率分布\n",
    "# -------------------------------\n",
    "# softmax 沿最后一维 dim=-1，将 logits 转为概率分布\n",
    "# 每个 token 在词表中每个位置的概率之和为 1\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "\n",
    "# 输出概率张量的形状\n",
    "# shape: [batch_size, seq_len, vocab_size]\n",
    "print(\"Probas shape:\", probas.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# 获取概率最大的位置索引，即预测的 token id\n",
    "# -------------------------------\n",
    "# torch.argmax: 返回沿指定维度最大值的索引\n",
    "# dim=-1 表示在词表维度上取最大值\n",
    "# keepdim=True 保持维度，方便后续操作\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "\n",
    "# 输出预测的 token ids\n",
    "print(\"Token IDs:\\n\", token_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4072c-21ed-4df7-8721-dd2535362573",
   "metadata": {},
   "source": [
    "- 如果我们对这些标记进行解码，会发现它们与我们希望模型预测的标记（即目标标记）有很大差异：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c990ead6-53cd-49a7-a6d1-14d8c1518249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 打印第一条样本的目标文本\n",
    "# -------------------------------\n",
    "# targets[0] 取第一条样本的 target token IDs，形状 [seq_len]\n",
    "# token_ids_to_text 函数将 token ID 列表解码为可读文本\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 打印第一条样本模型预测输出的文本\n",
    "# -------------------------------\n",
    "# token_ids[0] 取第一条样本的预测 token IDs，形状 [seq_len, 1]\n",
    "# flatten() 将 [seq_len,1] 压缩为 [seq_len]，方便解码\n",
    "# token_ids_to_text 将 token IDs 解码为文本\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53eb8a7-070e-46d6-930c-314ba55a6ff2",
   "metadata": {},
   "source": [
    "- 这是因为模型尚未经过训练  \n",
    "- 为了训练模型，我们需要知道它与正确预测（目标值）之间的差距\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90592f-0d5d-4ec8-9ff5-e7675beab10e",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/06.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7251bf5-a079-4782-901d-68c9225d3157",
   "metadata": {},
   "source": [
    "- 与目标索引对应的标记概率如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
    "outputId": "41c946a2-c458-433e-a53d-5e7e89d9dddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 选择 batch 中的第一条文本（索引 0）\n",
    "# -------------------------------\n",
    "text_idx = 0\n",
    "\n",
    "# probas 的 shape 是 [batch_size, num_tokens, vocab_size]\n",
    "# targets[text_idx] 是第一条文本的目标 token IDs, shape [num_tokens]\n",
    "# probas[text_idx, [0,1,2], targets[text_idx]] \n",
    "#   - [0,1,2] 指明选取第一条文本的每个 token 位置\n",
    "#   - targets[text_idx] 给出对应位置的正确 token ID\n",
    "#   - 结果是第一条文本每个目标 token 的预测概率\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "# -------------------------------\n",
    "# 选择 batch 中的第二条文本（索引 1）\n",
    "# -------------------------------\n",
    "text_idx = 1\n",
    "\n",
    "# 同理，获取第二条文本每个目标 token 的预测概率\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e89a19-73c2-4e49-93b4-861f699f1cbf",
   "metadata": {},
   "source": [
    "- 我们希望最大化所有这些值，使它们尽可能接近概率 1。  \n",
    "- 在数学优化中，最大化概率的对数（logarithm of the probability）要比直接最大化概率本身更容易实现；这一部分超出了本书的讨论范围，但我在这里录制了一段更详细的讲解视频：[L8.2 Logistic Regression Loss Function](https://www.youtube.com/watch?v=GxJe0DZvydM)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
    "outputId": "1bf18e79-1246-4eab-efd8-12b328c78678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 将第一条文本和第二条文本的目标 token 概率拼接在一起\n",
    "# torch.cat 默认沿第 0 维拼接，即将两个一维张量连接成一个一维张量\n",
    "# -------------------------------\n",
    "all_target_probas = torch.cat((target_probas_1, target_probas_2))\n",
    "\n",
    "# -------------------------------\n",
    "# 对拼接后的目标 token 概率取自然对数\n",
    "# log(p) 是计算交叉熵损失或负对数似然的关键步骤\n",
    "# -------------------------------\n",
    "log_probas = torch.log(all_target_probas)\n",
    "\n",
    "# 打印结果\n",
    "print(log_probas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4261441-a511-4633-9c4c-67998af31b84",
   "metadata": {},
   "source": [
    "- 接下来，我们计算平均对数概率：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b003797-161b-4d98-81dc-e68320e09fec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b003797-161b-4d98-81dc-e68320e09fec",
    "outputId": "a447fe9c-7e27-40ed-f1fb-51210e3f7cc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 计算所有目标 token log-probabilities 的平均值\n",
    "# torch.mean() 会将张量中的所有元素取平均\n",
    "# -------------------------------\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "\n",
    "# 打印结果\n",
    "print(avg_log_probas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d51994-ad17-4ba3-a6ec-f588b4b13585",
   "metadata": {},
   "source": [
    "- 我们的目标是通过优化模型权重，使这个平均对数概率（average log probability）尽可能大。  \n",
    "- 由于取了对数，理论上的最大值为 0，而当前模型的结果距离 0 仍然相差较远。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de388a1-8a0a-4c94-8894-9041dc6ad514",
   "metadata": {},
   "source": [
    "- 在深度学习中，我们通常不会直接最大化平均对数概率（average log-probability），而是遵循标准做法，最小化其“负的平均对数概率”值。  \n",
    "  在我们的例子中，与其最大化 -10.7722 使其接近 0，不如最小化 10.7722 使其接近 0。  \n",
    "- 这个 -10.7722 的相反数（即 10.7722）在深度学习中也被称为 **交叉熵损失（cross-entropy loss）**。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "176ddf35-1c5f-4d7c-bf17-70f3e7069bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 将平均对数概率取负\n",
    "# -------------------------------\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "\n",
    "# 打印结果\n",
    "print(neg_avg_log_probas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eeb868-abd8-4028-82db-107546bf7c2c",
   "metadata": {},
   "source": [
    "- PyTorch 已经实现了一个 `cross_entropy` 函数，用于执行上述步骤\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd24b7f-b760-47ad-bc84-86d13794aa54",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/07.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aaf9dd-3ee6-42bf-a63f-6e93dbfb989d",
   "metadata": {},
   "source": [
    "- 在应用 `cross_entropy` 函数之前，我们先检查 logits 和目标值（targets）的形状\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
    "outputId": "43fd802a-8136-4b35-df0d-f61a5d4cb561"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# 打印 logits 的形状\n",
    "# logits 是模型输出的原始分数（未经过 softmax）\n",
    "# 形状为 (batch_size, num_tokens, vocab_size)\n",
    "# - batch_size: 批量中样本数量\n",
    "# - num_tokens: 每个样本中的 token 数量（序列长度）\n",
    "# - vocab_size: 模型词表大小（每个 token 的预测分布）\n",
    "# --------------------------------------\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "\n",
    "# --------------------------------------\n",
    "# 打印目标 targets 的形状\n",
    "# targets 是对应的真实 token 索引\n",
    "# 形状为 (batch_size, num_tokens)\n",
    "# - batch_size: 批量中样本数量\n",
    "# - num_tokens: 每个样本中的 token 数量\n",
    "# --------------------------------------\n",
    "print(\"Targets shape:\", targets.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3d65f0-6566-4865-93e4-0c0bcb10cd06",
   "metadata": {},
   "source": [
    "- 对于 PyTorch 中的 `cross_entropy` 函数，我们需要将这些张量在批量维度上展开（flatten）：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
    "outputId": "0b2b778b-02fb-43b2-c879-adc59055a7d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 将 logits 展平 (flatten) 以便计算交叉熵损失\n",
    "# logits 的原始形状为 (batch_size, num_tokens, vocab_size)\n",
    "# flatten(0, 1) 表示把第 0 维（batch_size）和第 1 维（num_tokens）合并为一维\n",
    "# 结果形状为 (batch_size * num_tokens, vocab_size)\n",
    "# ---------------------------------------------------\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 将 targets 展平\n",
    "# targets 原始形状为 (batch_size, num_tokens)\n",
    "# flatten() 将其展平为 (batch_size * num_tokens,)\n",
    "# 这样可以和展平后的 logits 一一对应，用于计算交叉熵损失\n",
    "# ---------------------------------------------------\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 打印展平后的 logits 和 targets 的形状\n",
    "# logits_flat: (batch_size * num_tokens, vocab_size)\n",
    "# targets_flat: (batch_size * num_tokens,)\n",
    "# ---------------------------------------------------\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4921a57f-3a79-473e-a863-6d63b495010f",
   "metadata": {},
   "source": [
    "- 注意，`targets` 是 token ID，同时也表示我们希望在 logits 张量中最大化的索引位置。  \n",
    "- PyTorch 中的 `cross_entropy` 函数会自动处理 softmax 和对数概率（log-probability）的计算，并在 logits 中对应的 token 索引上进行优化。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
    "outputId": "c0be634a-2c65-4ff7-a73f-1bfc2e406ba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 使用 PyTorch 的函数式接口计算交叉熵损失\n",
    "# logits_flat: 展平后的模型输出，形状为 (batch_size * num_tokens, vocab_size)\n",
    "# targets_flat: 展平后的目标 token IDs，形状为 (batch_size * num_tokens,)\n",
    "# torch.nn.functional.cross_entropy 会对 logits 自动做 softmax，并计算每个 token 的负对数似然\n",
    "# ---------------------------------------------------\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 打印交叉熵损失值\n",
    "# loss 是一个标量张量，表示 batch 内所有 token 的平均负对数似然\n",
    "# 值越小，表示模型预测越接近目标\n",
    "# ---------------------------------------------------\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f15ce17-fd7b-4d8e-99da-b237523a7a80",
   "metadata": {},
   "source": [
    "- 与交叉熵损失相关的一个概念是大型语言模型（LLM）的困惑度（perplexity）  \n",
    "- 困惑度就是交叉熵损失的指数值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "168952a1-b964-4aa7-8e49-966fa26add54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "168952a1-b964-4aa7-8e49-966fa26add54",
    "outputId": "a0a692c1-6412-4068-8aa5-8858548141eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 困惑度（Perplexity）计算\n",
    "# 困惑度是语言模型常用的评价指标，它衡量模型对目标序列的不确定性\n",
    "# 对于 N 个 token 的平均负对数似然 loss，perplexity 定义为：\n",
    "#   perplexity = exp(loss)\n",
    "# loss 越小，perplexity 越接近 1，表示模型越“自信”，预测越准确\n",
    "# ---------------------------------------------------\n",
    "perplexity = torch.exp(loss)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 打印困惑度\n",
    "# 这是一个标量，越小表示模型性能越好\n",
    "# ---------------------------------------------------\n",
    "print(perplexity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ae26dd-d77e-41fd-b924-6bd103dd4ee7",
   "metadata": {},
   "source": [
    "- 困惑度（perplexity）通常被认为更易于理解，因为它可以被看作模型在每一步对词汇表的不确定性有效大小（在上面的例子中，即 48,725 个单词或 token）。  \n",
    "- 换句话说，困惑度衡量了模型预测的概率分布与数据集中单词的实际分布匹配的程度。  \n",
    "- 类似于损失（loss），较低的困惑度表示模型的预测更接近实际分布。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487",
   "metadata": {
    "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487"
   },
   "source": [
    "### 5.1.3 计算训练集和验证集损失\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530da89e-2448-436c-8f1b-28e8a31ef85c",
   "metadata": {},
   "source": [
    "- 我们使用了一个相对较小的数据集来训练 LLM（实际上只有一个短篇故事）。  \n",
    "- 原因如下：  \n",
    "  - 你可以在笔记本电脑上几分钟内运行代码示例，无需配备合适的 GPU。  \n",
    "  - 训练速度相对较快（几分钟而不是几周），这对教学目的非常适合。  \n",
    "  - 我们使用的是公共领域（public domain）的文本，可以安全地包含在 GitHub 仓库中，不会侵犯使用权，也不会使仓库体积过大。\n",
    "\n",
    "- 举例来说，Llama 2 7B 在 2 万亿 token 上训练时，需要在 A100 GPU 上耗费 184,320 GPU 小时。  \n",
    "  - 撰写本文时，AWS 上 8xA100 云服务器的小时费用大约为 \\$30。  \n",
    "  - 粗略计算，训练这个 LLM 的成本为 184,320 / 8 * \\$30 = \\$690,000。\n",
    "\n",
    "- 下文中，我们使用与第 2 章相同的数据集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# 下载并读取文本文件\n",
    "# 如果本地不存在指定文件，则从网络下载；否则直接读取本地文件\n",
    "# ===================================================\n",
    "\n",
    "import os       # 用于文件路径检查\n",
    "import requests # 用于发送 HTTP 请求\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 设置文件名和下载 URL\n",
    "# file_path: 本地文件名\n",
    "# url: 网络资源地址（原书中的文本文件）\n",
    "# ---------------------------------------------------\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 检查本地文件是否存在\n",
    "# os.path.exists(file_path) 返回 True 表示文件已存在\n",
    "# ---------------------------------------------------\n",
    "if not os.path.exists(file_path):\n",
    "    # 如果文件不存在，则通过 HTTP GET 请求下载文件\n",
    "    response = requests.get(url, timeout=30)  # timeout=30 秒，防止网络阻塞\n",
    "    response.raise_for_status()               # 如果请求失败（如 404/500），抛出异常\n",
    "    text_data = response.text                 # 获取文本内容\n",
    "\n",
    "    # 将下载的文本写入本地文件\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    # 如果文件已存在，则直接读取本地文件内容\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 说明：\n",
    "# 原书中使用 urllib.request 下载文件：\n",
    "#   import urllib.request\n",
    "#   with urllib.request.urlopen(url) as response:\n",
    "#       text_data = response.read().decode('utf-8')\n",
    "# 但是 urllib 可能会遇到 VPN 或 TLS 协议问题。\n",
    "# 使用 requests 更稳健、兼容性更好。\n",
    "# ---------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379330f1-80f4-4e34-8724-41d892b04cee",
   "metadata": {},
   "source": [
    "- 通过打印前99个和后99个字符，快速检查文本是否加载正确\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6kgJbe4ehI4q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "6kgJbe4ehI4q",
    "outputId": "9ff31e88-ee37-47e9-ee64-da6eb552f46f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 打印文本的前 99 个字符，用于快速查看文件内容\n",
    "# text_data: 前面下载或读取的完整文本字符串\n",
    "# text_data[:99]: 切片操作，取从索引 0 到索引 98 的字符（总共 99 个字符）\n",
    "# print(): 输出到屏幕\n",
    "# ---------------------------------------------------\n",
    "print(text_data[:99])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "j2XPde_ThM_e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "j2XPde_ThM_e",
    "outputId": "a900c1b9-9a87-4078-968b-a5721deda5cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 打印文本的最后 99 个字符，用于快速查看文件结尾内容\n",
    "# text_data: 前面下载或读取的完整文本字符串\n",
    "# text_data[-99:]: 切片操作，取从倒数第 99 个字符到最后的所有字符\n",
    "# print(): 输出到屏幕\n",
    "# ---------------------------------------------------\n",
    "print(text_data[-99:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
    "outputId": "c2a25334-21ca-486e-8226-0296e5fc6486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# 计算文本的总字符数和总 token 数量\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# len(text_data)：返回字符串 text_data 的长度，即文本中的字符总数\n",
    "total_characters = len(text_data)\n",
    "\n",
    "# tokenizer.encode(text_data)：将文本编码为 token ID 列表\n",
    "# len(...)：计算 token 列表的长度，即文本被分词后的 token 总数\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "# 打印总字符数\n",
    "print(\"Characters:\", total_characters)\n",
    "\n",
    "# 打印总 token 数量\n",
    "print(\"Tokens:\", total_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8830cb9-90f6-4e7c-8620-beeabc2d39f7",
   "metadata": {},
   "source": [
    "- 该文本共有 5,145 个标记（tokens），对于训练大型语言模型（LLM）来说非常短，但这只是用于教学目的（我们稍后还会加载预训练权重）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedcad87-a0e8-4b9d-ac43-4e927ccbb50f",
   "metadata": {},
   "source": [
    "- 接下来，我们将数据集划分为训练集和验证集，并使用第 2 章的数据加载器（data loaders）来准备 LLM 训练的批次（batches）。  \n",
    "- 为了可视化，下面的图假设 `max_length=6`，但在训练加载器中，我们将 `max_length` 设置为 LLM 所支持的上下文长度（context length）。  \n",
    "- 下图仅为简化，仅展示了输入 token：  \n",
    "  - 由于我们训练 LLM 以预测文本中的下一个单词，目标（targets）看起来与这些输入相同，只是目标向右平移了一个位置。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/09.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0959c855-f860-4358-8b98-bc654f047578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "# 或者从 PyPI 包中导入：\n",
    "# from llms_from_scratch.ch02 import create_dataloader_v1\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 设置训练集与验证集比例\n",
    "# -------------------------------------------------------\n",
    "train_ratio = 0.90  # 90% 数据用于训练，10% 用于验证\n",
    "split_idx = int(train_ratio * len(text_data))  # 计算切分索引位置\n",
    "train_data = text_data[:split_idx]            # 训练集数据\n",
    "val_data = text_data[split_idx:]              # 验证集数据\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 设置随机种子，确保可复现\n",
    "# -------------------------------------------------------\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# =======================================================\n",
    "# 创建训练集 DataLoader\n",
    "# =======================================================\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,                              # 原始文本训练数据\n",
    "    batch_size=2,                             # 每个 batch 取 2 条样本\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],  # 每条样本最大 token 长度\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],      # 步长（stride），这里等于 max_length，相当于不重叠\n",
    "    drop_last=True,                           # 丢弃最后一个不足 batch_size 的 batch\n",
    "    shuffle=True,                             # 打乱样本顺序，用于训练\n",
    "    num_workers=0                              # DataLoader 的工作线程数（0 表示在主进程运行）\n",
    ")\n",
    "\n",
    "# =======================================================\n",
    "# 创建验证集 DataLoader\n",
    "# =======================================================\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,                                # 原始文本验证数据\n",
    "    batch_size=2,                             # 每个 batch 取 2 条样本\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],  # 每条样本最大 token 长度\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],      # 步长\n",
    "    drop_last=False,                          # 验证集不丢弃最后一个不足 batch_size 的 batch\n",
    "    shuffle=False,                            # 验证集不打乱顺序\n",
    "    num_workers=0                              # DataLoader 的工作线程数\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f37b3eb0-854e-4895-9898-fa7d1e67566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# 检查训练集和验证集是否有足够的 token 来构建 DataLoader\n",
    "# 防止 context_length 太大而导致某个 loader 没有足够 token\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# 检查训练集 token 数量是否足够\n",
    "if total_tokens * train_ratio < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\n",
    "        \"Not enough tokens for the training loader. \"\n",
    "        \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "        \"increase the `training_ratio`\"\n",
    "    )\n",
    "    # 解释：\n",
    "    # total_tokens * train_ratio：训练集中的 token 总数\n",
    "    # GPT_CONFIG_124M[\"context_length\"]：模型支持的最大上下文长度\n",
    "    # 如果训练集 token 数量小于 context_length，DataLoader 无法生成有效 batch\n",
    "\n",
    "# 检查验证集 token 数量是否足够\n",
    "if total_tokens * (1 - train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\n",
    "        \"Not enough tokens for the validation loader. \"\n",
    "        \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "        \"decrease the `training_ratio`\"\n",
    "    )\n",
    "    # 解释：\n",
    "    # total_tokens * (1 - train_ratio)：验证集中的 token 总数\n",
    "    # 同样，如果验证集 token 数量小于 context_length，DataLoader 无法生成有效 batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac3296-a4d1-4303-9ac5-376518960c33",
   "metadata": {},
   "source": [
    "- 我们使用相对较小的批量大小，以降低计算资源需求，同时因为数据集本身非常小  \n",
    "- 例如，Llama 2 7B 的训练批量大小为 1024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0514d-b990-4dc0-9afb-7721993284a0",
   "metadata": {},
   "source": [
    "- 可选检查，确认数据是否正确加载：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 检查 DataLoader 输出形状（Sanity Check）\n",
    "# ==============================================\n",
    "\n",
    "# 打印“训练集加载器”的提示信息\n",
    "print(\"Train loader:\")\n",
    "\n",
    "# 遍历 train_loader 中的批次数据\n",
    "# 每次迭代会返回两个张量：\n",
    "#   x —— 输入序列（input tokens）\n",
    "#   y —— 目标序列（target tokens）\n",
    "for x, y in train_loader:\n",
    "    # 打印当前批次中 x 和 y 的形状\n",
    "    print(x.shape, y.shape)\n",
    "    # 通常形状为：\n",
    "    #   x: [batch_size, context_length]\n",
    "    #   y: [batch_size, context_length]\n",
    "    # 说明每个批次都有 batch_size 条训练样本，\n",
    "    # 每个样本包含 context_length 个 token。\n",
    "\n",
    "# 空行用于分隔输出结果\n",
    "print(\"\\nValidation loader:\")\n",
    "\n",
    "# 遍历验证集加载器\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    # 验证集的形状应该与训练集一致，\n",
    "    # 只是数据内容不同，不进行随机打乱（shuffle=False）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9b1a4-863d-456f-a8dd-c07fb5c024ed",
   "metadata": {},
   "source": [
    "- 另一个可选检查，确认标记（token）的数量是否在预期范围内：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb860488-5453-41d7-9870-23b723f742a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb860488-5453-41d7-9870-23b723f742a0",
    "outputId": "96b9451a-9557-4126-d1c8-51610a1995ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 计算训练集与验证集中的 token 数量\n",
    "# ==========================================\n",
    "\n",
    "# 初始化训练集 token 计数器\n",
    "train_tokens = 0\n",
    "\n",
    "# 遍历训练集加载器 train_loader\n",
    "# 每次从 DataLoader 中取出一个 batch（批次）\n",
    "# input_batch: 模型输入（token 序列）\n",
    "# target_batch: 目标输出（通常是输入右移一位的 token 序列）\n",
    "for input_batch, target_batch in train_loader:\n",
    "    # input_batch.numel() 返回该批次中所有元素的总数量\n",
    "    # numel = number of elements，即 (batch_size × context_length)\n",
    "    train_tokens += input_batch.numel()  # 累加该批次的 token 数量\n",
    "\n",
    "# 初始化验证集 token 计数器\n",
    "val_tokens = 0\n",
    "\n",
    "# 遍历验证集加载器 val_loader\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()  # 同样计算验证集 token 数量\n",
    "\n",
    "# ==========================================\n",
    "# 打印结果\n",
    "# ==========================================\n",
    "\n",
    "# 输出训练集中的总 token 数\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "\n",
    "# 输出验证集中的总 token 数\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "\n",
    "# 输出所有 token（训练集 + 验证集）的总数\n",
    "print(\"All tokens:\", train_tokens + val_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3085e8-665e-48eb-bb41-cdde61537e06",
   "metadata": {},
   "source": [
    "- 接下来，我们实现一个实用函数，用于计算给定批次的交叉熵损失  \n",
    "- 此外，我们还实现第二个实用函数，用于计算数据加载器中用户指定数量批次的损失\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc",
   "metadata": {
    "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc"
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 函数 1：计算单个 batch 的交叉熵损失\n",
    "# =====================================================\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    \"\"\"\n",
    "    计算一个 batch 的交叉熵损失 (cross-entropy loss)\n",
    "\n",
    "    参数：\n",
    "    - input_batch: 张量，形状为 [batch_size, seq_len]，输入 token 序列\n",
    "    - target_batch: 张量，形状为 [batch_size, seq_len]，目标 token 序列\n",
    "    - model: 语言模型对象，例如 GPTModel\n",
    "    - device: 设备字符串，例如 \"cpu\" 或 \"cuda\"\n",
    "\n",
    "    返回：\n",
    "    - loss: 单个 batch 的交叉熵损失 (scalar 张量)\n",
    "    \"\"\"\n",
    "    # -----------------------------------------\n",
    "    # 将输入和目标移动到指定设备（CPU/GPU）\n",
    "    # -----------------------------------------\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 前向传播计算 logits\n",
    "    # logits 形状: [batch_size, seq_len, vocab_size]\n",
    "    # -----------------------------------------\n",
    "    logits = model(input_batch)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 计算交叉熵损失\n",
    "    # flatten(0,1) 将 logits 从 [batch, seq_len, vocab_size] \n",
    "    # 展平成 [batch*seq_len, vocab_size]\n",
    "    # target_batch.flatten() 将目标序列展平为 [batch*seq_len]\n",
    "    # 这样每个 token 都参与损失计算\n",
    "    # -----------------------------------------\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1),\n",
    "        target_batch.flatten()\n",
    "    )\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 函数 2：计算整个数据加载器（DataLoader）的平均损失\n",
    "# =====================================================\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    \"\"\"\n",
    "    计算一个 DataLoader 中若干 batch 的平均交叉熵损失\n",
    "\n",
    "    参数：\n",
    "    - data_loader: PyTorch DataLoader 对象，每个元素是 (input_batch, target_batch)\n",
    "    - model: 语言模型对象\n",
    "    - device: 设备字符串，例如 \"cpu\" 或 \"cuda\"\n",
    "    - num_batches: 可选，指定最多计算多少个 batch，如果为 None 则计算全部 batch\n",
    "\n",
    "    返回：\n",
    "    - avg_loss: 平均交叉熵损失 (float)\n",
    "    \"\"\"\n",
    "    total_loss = 0.  # 累计损失初始化为 0\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 如果 data_loader 为空，返回 NaN\n",
    "    # -----------------------------------------\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    \n",
    "    # -----------------------------------------\n",
    "    # 确定需要计算的 batch 数量\n",
    "    # -----------------------------------------\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # 如果指定的 num_batches 超过了数据加载器的长度，则取最小值\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 遍历数据加载器\n",
    "    # i: 当前 batch 索引\n",
    "    # input_batch, target_batch: 当前 batch 的输入和目标\n",
    "    # -----------------------------------------\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            # 计算当前 batch 的损失\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            # 累加损失\n",
    "            total_loss += loss.item()  # .item() 将张量转换为 Python float\n",
    "        else:\n",
    "            break  # 超过指定 batch 数量就退出循环\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 返回平均损失\n",
    "    # total_loss / num_batches\n",
    "    # -----------------------------------------\n",
    "    return total_loss / num_batches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0691332-84d0-48b3-b462-a885ddeb4fca",
   "metadata": {},
   "source": [
    "- 如果你的机器配备了支持 CUDA 的 GPU，LLM 将会在 GPU 上进行训练，而无需对代码进行任何修改  \n",
    "- 通过 `device` 设置，我们可以确保数据被加载到与 LLM 模型相同的设备上\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758347829183\n",
      "Validation loss: 10.981106758117676\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 选择设备（CPU 或 GPU）\n",
    "# =====================================================\n",
    "# 如果有 CUDA 可用，则使用 GPU；否则使用 CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -----------------------------\n",
    "# 备选方案（适用于 Apple Silicon 芯片，例如 M1/M2/M3）\n",
    "# 通过 MPS 支持可以比 CPU 快约 2 倍，但数值可能略有差异\n",
    "# -----------------------------\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda\")\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "# print(f\"Using {device} device.\")\n",
    "\n",
    "# =====================================================\n",
    "# 将模型移动到指定设备\n",
    "# 对 nn.Module 对象来说，无需重新赋值给 model\n",
    "# =====================================================\n",
    "model.to(device)\n",
    "\n",
    "# =====================================================\n",
    "# 设置随机种子以保证可重复性\n",
    "# 由于 DataLoader 内可能有 shuffle，这里固定种子可以保证每次输出一致\n",
    "# =====================================================\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# =====================================================\n",
    "# 在不计算梯度的上下文中计算训练/验证损失\n",
    "# 1. torch.no_grad() 用于禁用梯度计算，提高推理效率\n",
    "# 2. 我们此处只是评估模型损失，尚未进行训练\n",
    "# =====================================================\n",
    "with torch.no_grad():\n",
    "    # 计算训练集的平均交叉熵损失\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "\n",
    "    # 计算验证集的平均交叉熵损失\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "# =====================================================\n",
    "# 打印训练集和验证集损失\n",
    "# =====================================================\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43875e95-190f-4b17-8f9a-35034ba649ec",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/10.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9339f8d-00cb-4206-af67-58c32bd72055",
   "metadata": {
    "id": "b9339f8d-00cb-4206-af67-58c32bd72055"
   },
   "source": [
    "## 5.2 训练一个大型语言模型（LLM）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd",
   "metadata": {},
   "source": [
    "- 在本节中，我们最终实现 LLM 的训练代码。  \n",
    "- 我们重点关注一个简单的训练函数（如果你有兴趣在此训练函数中加入更高级的技巧，例如学习率预热（learning rate warmup）、余弦退火（cosine annealing）和梯度裁剪（gradient clipping），请参考 [附录 D](../../appendix-D/01_main-chapter-code)）。\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/11.webp\" width=300px>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "Mtp4gY0ZO-qq",
   "metadata": {
    "id": "Mtp4gY0ZO-qq"
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 简单 GPT 模型训练函数\n",
    "# =====================================================\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "        对 GPT 模型进行简单训练，并在训练过程中周期性评估损失与生成示例文本\n",
    "    参数：\n",
    "        model       : nn.Module，待训练的 GPT 模型\n",
    "        train_loader: DataLoader，训练集批次数据\n",
    "        val_loader  : DataLoader，验证集批次数据\n",
    "        optimizer   : 优化器（如 AdamW）\n",
    "        device      : torch.device，训练设备 (CPU / GPU)\n",
    "        num_epochs  : int，总训练轮数\n",
    "        eval_freq   : int，每多少步进行一次评估\n",
    "        eval_iter   : int，每次评估使用多少个 batch\n",
    "        start_context: str，生成示例文本的起始上下文\n",
    "        tokenizer   : tiktoken tokenizer，用于编码/解码文本\n",
    "    返回值：\n",
    "        train_losses       : list，每次评估的训练损失\n",
    "        val_losses         : list，每次评估的验证损失\n",
    "        track_tokens_seen  : list，训练过程中累计看到的 token 数\n",
    "    \"\"\"\n",
    "    \n",
    "    # 初始化记录列表\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # -----------------------------\n",
    "    # 训练主循环\n",
    "    # -----------------------------\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 将模型切换到训练模式（启用 dropout 等）\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # 清零上一步梯度，防止梯度累积\n",
    "            \n",
    "            # 计算当前 batch 的损失\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            \n",
    "            loss.backward()        # 反向传播计算梯度\n",
    "            optimizer.step()       # 更新模型参数\n",
    "            \n",
    "            # 累计已经看到的 token 数\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # -----------------------------\n",
    "            # 可选评估步骤：每 eval_freq 步评估一次\n",
    "            # -----------------------------\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                \n",
    "                # 打印训练信息\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # 每个 epoch 结束后生成示例文本\n",
    "        # -----------------------------\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 模型评估函数\n",
    "# =====================================================\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "        计算训练集与验证集的平均损失（仅前 eval_iter 个 batch）\n",
    "    参数：\n",
    "        model       : nn.Module，待评估的模型\n",
    "        train_loader: DataLoader，训练集\n",
    "        val_loader  : DataLoader，验证集\n",
    "        device      : torch.device\n",
    "        eval_iter   : int，评估时使用的 batch 数量\n",
    "    返回值：\n",
    "        train_loss  : float，训练集平均损失\n",
    "        val_loss    : float，验证集平均损失\n",
    "    \"\"\"\n",
    "    model.eval()  # 切换到评估模式（禁用 dropout）\n",
    "    with torch.no_grad():  # 禁用梯度计算，节省显存\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss   = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()  # 恢复训练模式\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 生成文本并打印的辅助函数\n",
    "# =====================================================\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "        从给定的起始上下文生成文本并打印\n",
    "    参数：\n",
    "        model        : nn.Module，训练中的 GPT 模型\n",
    "        tokenizer    : tiktoken tokenizer，用于编码/解码\n",
    "        device       : torch.device\n",
    "        start_context: str，文本生成起始字符串\n",
    "    \"\"\"\n",
    "    model.eval()  # 评估模式（禁用 dropout）\n",
    "    \n",
    "    # 获取模型支持的最大上下文长度\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    \n",
    "    # 将起始文本编码为 token 并移动到指定设备\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    \n",
    "    # 生成文本\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model,\n",
    "            idx=encoded,\n",
    "            max_new_tokens=50,  # 本例生成 50 个新 token\n",
    "            context_size=context_size\n",
    "        )\n",
    "    \n",
    "    # 解码生成的 token 为文本\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    \n",
    "    # 打印文本，去掉换行以便于教学显示\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    \n",
    "    model.train()  # 恢复训练模式\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47",
   "metadata": {},
   "source": [
    "- 现在，让我们使用前面定义的训练函数来训练这个大型语言模型（LLM）：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3422000b-7aa2-485b-92df-99372cd22311",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3422000b-7aa2-485b-92df-99372cd22311",
    "outputId": "0e046603-908d-4093-8ae5-ef2f632639fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.781, Val loss 9.933\n",
      "Ep 1 (Step 000005): Train loss 8.111, Val loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.661, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 5.961, Val loss 6.616\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Ep 3 (Step 000020): Train loss 5.726, Val loss 6.600\n",
      "Ep 3 (Step 000025): Train loss 5.201, Val loss 6.348\n",
      "Every effort moves you, and I had been.                                            \n",
      "Ep 4 (Step 000030): Train loss 4.417, Val loss 6.278\n",
      "Ep 4 (Step 000035): Train loss 4.069, Val loss 6.226\n",
      "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step 000040): Train loss 3.732, Val loss 6.160\n",
      "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
      "Ep 6 (Step 000045): Train loss 2.850, Val loss 6.179\n",
      "Ep 6 (Step 000050): Train loss 2.427, Val loss 6.141\n",
      "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
      "Ep 7 (Step 000055): Train loss 2.104, Val loss 6.134\n",
      "Ep 7 (Step 000060): Train loss 1.882, Val loss 6.233\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Ep 8 (Step 000065): Train loss 1.320, Val loss 6.238\n",
      "Ep 8 (Step 000070): Train loss 0.985, Val loss 6.242\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000075): Train loss 0.717, Val loss 6.293\n",
      "Ep 9 (Step 000080): Train loss 0.541, Val loss 6.393\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.391, Val loss 6.452\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# GPT 模型训练示例\n",
    "# =====================================================\n",
    "\n",
    "# -----------------------------\n",
    "# 可选：记录训练开始时间，用于计算总训练耗时\n",
    "# -----------------------------\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "\n",
    "# -----------------------------\n",
    "# 设置随机种子，保证可复现\n",
    "# -----------------------------\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# -----------------------------\n",
    "# 初始化 GPT 模型\n",
    "# -----------------------------\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "# 将模型移动到指定设备 (CPU / GPU / MPS)\n",
    "model.to(device)\n",
    "\n",
    "# -----------------------------\n",
    "# 定义优化器\n",
    "# -----------------------------\n",
    "# 使用 AdamW 优化器\n",
    "# lr=0.0004 表示学习率\n",
    "# weight_decay=0.1 表示权重衰减，用于正则化\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "# -----------------------------\n",
    "# 设置训练轮数\n",
    "# -----------------------------\n",
    "num_epochs = 10\n",
    "\n",
    "# -----------------------------\n",
    "# 调用训练函数开始训练\n",
    "# -----------------------------\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,            # 待训练的模型\n",
    "    train_loader,     # 训练集 DataLoader\n",
    "    val_loader,       # 验证集 DataLoader\n",
    "    optimizer,        # 优化器\n",
    "    device,           # 训练设备\n",
    "    num_epochs=num_epochs,    # 总训练轮数\n",
    "    eval_freq=5,             # 每 5 个 batch 进行一次评估\n",
    "    eval_iter=5,             # 每次评估取 5 个 batch 计算平均损失\n",
    "    start_context=\"Every effort moves you\",  # 每轮训练结束生成文本的起始上下文\n",
    "    tokenizer=tokenizer       # tokenizer，用于编码/解码文本\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 可选：计算训练总耗时\n",
    "# -----------------------------\n",
    "# end_time = time.time()\n",
    "# execution_time_minutes = (end_time - start_time) / 60\n",
    "# print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b86f0-b07d-40d7-b9d3-a9218917f204",
   "metadata": {},
   "source": [
    "- 请注意，在你的电脑上可能会得到略有不同的损失值（loss），如果它们大致相近（训练损失低于 1，验证损失低于 7），无需担心。  \n",
    "- 这些小差异通常可能由不同的 GPU 硬件、CUDA 版本或较新 PyTorch 版本中的微小变化导致。  \n",
    "- 即使在 CPU 上运行示例，也可能观察到轻微差异；造成这种差异的一个可能原因是 `nn.Dropout` 在不同操作系统上的行为不同，这取决于 PyTorch 的编译方式，详见 [PyTorch 问题追踪](https://github.com/pytorch/pytorch/issues/121595)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0WSRu2i0iHJE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "0WSRu2i0iHJE",
    "outputId": "9d36c61b-517d-4f07-a7e8-4563aff78b11"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 绘制训练与验证损失随训练轮数变化图\n",
    "# =====================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator  # 用于控制坐标轴刻度\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    \"\"\"\n",
    "    绘制训练损失和验证损失随训练轮数变化的图，并在上方添加“tokens seen”坐标轴。\n",
    "\n",
    "    参数：\n",
    "    - epochs_seen: 当前训练轮数对应的浮点序列（Tensor 或列表）\n",
    "    - tokens_seen: 累计训练 token 数量列表\n",
    "    - train_losses: 训练损失列表\n",
    "    - val_losses: 验证损失列表\n",
    "    \"\"\"\n",
    "    # 创建一个画布，大小为 (5 x 3) 英寸\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # -----------------------------\n",
    "    # 绘制训练和验证损失随 epochs 的曲线\n",
    "    # -----------------------------\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")        # 训练损失曲线\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")  # 验证损失曲线\n",
    "    ax1.set_xlabel(\"Epochs\")  # x 轴标签\n",
    "    ax1.set_ylabel(\"Loss\")    # y 轴标签\n",
    "    ax1.legend(loc=\"upper right\")  # 显示图例在右上角\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # x 轴只显示整数刻度\n",
    "\n",
    "    # -----------------------------\n",
    "    # 创建第二个 x 轴用于展示“Tokens seen”\n",
    "    # -----------------------------\n",
    "    ax2 = ax1.twiny()  # 创建共享 y 轴的上方 x 轴\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # 绘制透明曲线，仅用于对齐刻度\n",
    "    ax2.set_xlabel(\"Tokens seen\")  # 上方 x 轴标签\n",
    "\n",
    "    # -----------------------------\n",
    "    # 调整布局，避免标签和图像重叠\n",
    "    # -----------------------------\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # -----------------------------\n",
    "    # 保存绘图为 PDF 文件\n",
    "    # -----------------------------\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 显示图形\n",
    "    # -----------------------------\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 将训练轮数序列从 0 到总轮数 num_epochs 等间隔生成，与 train_losses 长度一致\n",
    "# -----------------------------\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "\n",
    "# -----------------------------\n",
    "# 调用函数绘制损失曲线\n",
    "# -----------------------------\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995",
   "metadata": {},
   "source": [
    "- 从上面的结果可以看到，模型一开始生成的是难以理解的词串，而到训练末期，它能够生成语法上大致正确的句子。  \n",
    "- 然而，根据训练集和验证集的损失情况，可以看出模型开始出现过拟合。  \n",
    "- 如果检查模型在训练末期生成的几段文本，会发现它们与训练集内容完全一致——模型只是记住了训练数据。  \n",
    "- 后面我们将介绍一些解码策略（decoding strategies），可以在一定程度上缓解这种记忆现象。  \n",
    "- 注意，这里的过拟合是因为我们使用的训练集非常非常小，同时对其迭代次数很多：  \n",
    "  - 这里的 LLM 训练主要是为了教学目的，我们主要想看到模型能够学习生成连贯文本。  \n",
    "  - 与其在大量昂贵硬件上花费数周或数月训练这个模型，我们后面将直接加载预训练权重。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb380c42-b31c-4ee1-b8b9-244094537272",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/13.webp\" width=350px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de713235-1561-467f-bf63-bf11ade383f0",
   "metadata": {},
   "source": [
    "**如果你有兴趣在这个训练函数中加入更高级的训练技巧，例如学习率预热（learning rate warmup）、余弦退火（cosine annealing）以及梯度裁剪（gradient clipping），请参阅 [附录 D](../../appendix-D/01_main-chapter-code)。**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5cdf2f-09a5-4eb0-a20a-d7aac5c14c2c",
   "metadata": {},
   "source": [
    "**如果你希望使用更大的训练数据集并进行更长时间的训练，请参阅 [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)。**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f45fc-bf78-42f2-bd24-2355db41b28f",
   "metadata": {
    "id": "699f45fc-bf78-42f2-bd24-2355db41b28f"
   },
   "source": [
    "## 5.3 解码策略以控制随机性\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be9086e-2c27-41da-97d0-49137d0ba3c7",
   "metadata": {},
   "source": [
    "- 对于像我们上面训练的这个较小的 GPT 模型来说，推理（inference）成本相对较低，因此即使你之前使用 GPU 训练，也不必使用 GPU 进行推理。  \n",
    "- 使用我们在前面简单训练函数中使用的 `generate_text_simple` 函数（来自上一章），我们可以一次生成一个单词（或 token）的新文本。  \n",
    "- 如第 5.1.2 节所述，下一个生成的 token 是词汇表中概率分数最高的 token。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2734cee0-f6f9-42d5-b71c-fa7e0ef28b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed lun\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 使用 CPU 进行推理（inference），因为模型较小，推理开销低\n",
    "# 并确保读者在本书后续章节中得到一致的结果\n",
    "# =====================================================\n",
    "inference_device = torch.device(\"cpu\")  # 指定设备为 CPU\n",
    "\n",
    "# 将模型移动到 CPU 上\n",
    "model.to(inference_device)\n",
    "\n",
    "# 设置模型为评估模式（禁用 dropout 等训练特定行为）\n",
    "model.eval()\n",
    "\n",
    "# 初始化 GPT-2 分词器\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# -----------------------------\n",
    "# 调用简单文本生成函数 generate_text_simple\n",
    "# -----------------------------\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),  \n",
    "    # 输入上下文序列 \"Every effort moves you\"，先编码成 token ID，再移动到 CPU\n",
    "    max_new_tokens=25,       # 新生成 token 的最大数量\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]  \n",
    "    # 上下文窗口长度，确保模型仅使用最后 context_size 个 token 进行预测\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 将生成的 token IDs 转回可读文本\n",
    "# -----------------------------\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25dbe31-bb7c-4893-b25b-47d0492d4aa4",
   "metadata": {},
   "source": [
    "- 即使我们多次执行上面的 `generate_text_simple` 函数，LLM 生成的输出仍然会完全相同。  \n",
    "- 现在我们引入两个概念，即所谓的解码策略（decoding strategies），用于改进 `generate_text_simple` 函数：**温度缩放（temperature scaling）** 和 **Top-k 采样（top-k sampling）**。  \n",
    "- 这些策略可以让模型控制生成文本的随机性和多样性。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb6f380-a798-4fd9-825c-17b7cd29a994",
   "metadata": {},
   "source": [
    "### 5.3.1 温度缩放（Temperature Scaling）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4f53c-0612-43d3-aa82-52447eac50fa",
   "metadata": {},
   "source": [
    "- 之前，我们总是使用 `torch.argmax` 选择概率最高的 token 作为下一个 token。  \n",
    "- 为了增加多样性，我们可以使用 `torch.multinomial(probs, num_samples=1)` 从概率分布中采样下一个 token。  \n",
    "- 在这里，每个索引被选中的概率与输入张量中对应的概率值成正比。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7531bae-d5de-44c0-bc78-78fed077e22a",
   "metadata": {},
   "source": [
    "- 下面是一个关于“生成下一个 token”的小回顾，这里为了说明原理，我们假设词汇表（vocabulary）非常小：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01a5ce39-3dc8-4c35-96bc-6410a1e42412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 定义词汇表（vocab）和其反向映射（inverse_vocab）\n",
    "# =====================================================\n",
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "# 生成反向字典：从 token_id -> token 字符串\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# =====================================================\n",
    "# 假设输入文本为 \"every effort moves you\"\n",
    "# 模型返回下一个 token 的 logits（未归一化得分）\n",
    "# =====================================================\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "# Shape: (vocab_size,) = (9,)\n",
    "\n",
    "# =====================================================\n",
    "# 将 logits 转换为概率分布\n",
    "# softmax 将 logits 归一化为总和为 1 的概率\n",
    "# =====================================================\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "# probas[i] 表示生成第 i 个 token 的概率\n",
    "\n",
    "# =====================================================\n",
    "# 选取概率最大的 token 作为下一个生成 token（贪心策略）\n",
    "# =====================================================\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "# torch.argmax 返回最大概率的索引\n",
    "# .item() 将 0-d tensor 转为 Python int\n",
    "\n",
    "# =====================================================\n",
    "# 根据反向字典查找对应的 token\n",
    "# =====================================================\n",
    "print(inverse_vocab[next_token_id])\n",
    "# 输出下一个生成的 token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6400572f-b3c8-49e2-95bc-433e55c5b3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 固定随机种子，保证采样结果可复现\n",
    "# =====================================================\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# =====================================================\n",
    "# 使用多项式采样 (multinomial) 从概率分布中抽取一个 token\n",
    "# probas: 各 token 的概率分布\n",
    "# num_samples=1: 抽取 1 个 token\n",
    "# 返回的是 tensor，需要 .item() 转为 Python int\n",
    "# =====================================================\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "\n",
    "# =====================================================\n",
    "# 根据反向字典查找对应的 token\n",
    "# =====================================================\n",
    "print(inverse_vocab[next_token_id])\n",
    "# 输出根据概率采样得到的下一个 token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d0a27-830b-42b5-9986-6d1a7de04dd9",
   "metadata": {},
   "source": [
    "- 与其使用 `torch.argmax` 来确定概率最高的 token，我们可以使用 `torch.multinomial(probas, num_samples=1)`，从 softmax 概率分布中**按概率进行采样**，以此决定下一个最可能的 token。  \n",
    "- 为了演示这个原理，我们来看看当我们使用原始的 softmax 概率分布重复采样 1,000 次时会发生什么：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b23b863e-252a-403c-b5b1-62bc0a42319f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    \"\"\"\n",
    "    演示概率采样（Multinomial Sampling）效果：\n",
    "    对给定的 token 概率分布进行多次采样，并统计每个 token 被选中的次数。\n",
    "    \n",
    "    参数：\n",
    "    - probas: torch.Tensor，形状 [vocab_size]\n",
    "        表示每个 token 的概率（一般来自 softmax 输出），\n",
    "        所有元素之和应为 1。\n",
    "    \"\"\"\n",
    "    \n",
    "    # ------------------------------\n",
    "    # 固定随机种子以保证可复现\n",
    "    # ------------------------------\n",
    "    # 这里使用 123 作为随机种子\n",
    "    # 这样每次运行都会得到相同的采样序列，便于教学演示\n",
    "    torch.manual_seed(123)\n",
    "    \n",
    "    # ------------------------------\n",
    "    # 多次从概率分布中采样 token\n",
    "    # ------------------------------\n",
    "    # 使用列表生成式进行 1000 次采样\n",
    "    # torch.multinomial(input, num_samples=1)\n",
    "    # - input: 概率分布 tensor，长度为 vocab_size\n",
    "    # - num_samples: 每次采样多少个元素，这里为 1，即每次只选一个 token\n",
    "    # - 返回值: tensor，长度为 num_samples，每个元素是对应 token 的索引\n",
    "    # .item() 将 tensor 转换为 Python 整数\n",
    "    sample = [\n",
    "        torch.multinomial(probas, num_samples=1).item()  # 采样一个 token id\n",
    "        for i in range(1_000)                            # 重复采样 1000 次\n",
    "    ]\n",
    "    \n",
    "    # ------------------------------\n",
    "    # 统计每个 token 被采样的次数\n",
    "    # ------------------------------\n",
    "    # torch.bincount(input, minlength)\n",
    "    # - input: 一个包含非负整数的 1D tensor\n",
    "    # - minlength: 返回的计数 tensor 的长度（保证包含 vocab_size 个 token）\n",
    "    # 返回值: 长度为 minlength 的 tensor，tensor[i] 表示 token i 出现的次数\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    \n",
    "    # ------------------------------\n",
    "    # 打印每个 token 的采样次数\n",
    "    # ------------------------------\n",
    "    # enumerate: 遍历 sampled_ids，i 是 token 索引，freq 是出现次数\n",
    "    # inverse_vocab[i] 根据 token id 得到对应文本\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")  # 打印格式：出现次数 x token\n",
    "    \n",
    "# ------------------------------\n",
    "# 调用函数示例\n",
    "# ------------------------------\n",
    "print_sampled_tokens(probas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7d9cf-a26d-4d9a-8664-4af1efa73832",
   "metadata": {},
   "source": [
    "- 我们可以通过一个称为温度缩放（temperature scaling）的概念来控制分布和选择过程。  \n",
    "- “温度缩放”其实就是一个术语，指的是将 logits 除以一个大于 0 的数。  \n",
    "- 温度大于 1 时，经过 softmax 后，token 的概率分布会更加均匀。  \n",
    "- 温度小于 1 时，经过 softmax 后，分布会更加自信（更尖锐或更集中）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b5399",
   "metadata": {},
   "source": [
    "- 请注意，经过 dropout 后的输出可能会因操作系统不同而有所差异；你可以在 [PyTorch 问题追踪](https://github.com/pytorch/pytorch/issues/121595) 中了解更多关于这种不一致性的内容。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0759e4c8-5362-467c-bec6-b0a19d1ba43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 1: tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
      "        1.0120e-04, 3.5758e-01, 4.0122e-03])\n",
      "Temperature 0.1: tensor([1.8530e-10, 3.5189e-26, 2.6890e-38, 9.9099e-01, 5.7569e-23, 4.4220e-37,\n",
      "        2.9718e-38, 9.0133e-03, 2.8514e-22])\n",
      "Temperature 5: tensor([0.1546, 0.0750, 0.0429, 0.2421, 0.0869, 0.0454, 0.0430, 0.2203, 0.0898])\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 定义带温度系数的 softmax 函数\n",
    "# -----------------------------\n",
    "def softmax_with_temperature(logits, temperature):\n",
    "    \"\"\"\n",
    "    logits: 1D 张量，表示模型输出的各个 token 的未归一化分数（logits）\n",
    "    temperature: 温度系数，控制采样分布的“平滑度”或“尖锐度”\n",
    "                 - temperature < 1 → 分布更尖锐，概率集中在最大值附近\n",
    "                 - temperature > 1 → 分布更平坦，更随机\n",
    "    返回值: softmax 后的概率分布张量，和 logits 维度一致\n",
    "    \"\"\"\n",
    "    # 将 logits 按温度缩放\n",
    "    # 注意：temperature 为 1 时，不改变 logits；temperature < 1 会放大 logits 差异\n",
    "    scaled_logits = logits / temperature\n",
    "\n",
    "    # 对缩放后的 logits 计算 softmax\n",
    "    # dim=0 表示对整个一维张量计算 softmax\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 定义不同的温度值\n",
    "# -----------------------------\n",
    "temperatures = [1, 0.1, 5]  # 三种情况：\n",
    "# 1: 原始 logits\n",
    "# 0.1: 极低温度 → 高置信度，概率更集中于最大 logits\n",
    "# 5: 高温度 → 低置信度，概率更均匀，更随机\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 对每个温度值计算缩放后的概率\n",
    "# -----------------------------\n",
    "scaled_probas = [\n",
    "    softmax_with_temperature(next_token_logits, T)  # 调用上面定义的函数\n",
    "    for T in temperatures\n",
    "]\n",
    "\n",
    "# scaled_probas 是一个列表，长度 = len(temperatures)\n",
    "# 每个元素都是与 next_token_logits 形状相同的一维概率张量\n",
    "# 你可以用下面方式查看结果：\n",
    "for T, prob in zip(temperatures, scaled_probas):\n",
    "    print(f\"Temperature {T}: {prob}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e66e613-4aca-4296-a984-ddd0d80c6578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 绘制不同温度下的概率分布柱状图\n",
    "# -----------------------------\n",
    "\n",
    "# x 轴的刻度：每个 token 对应一个整数位置\n",
    "# torch.arange(len(vocab)) 会生成 [0, 1, 2, ..., len(vocab)-1]\n",
    "x = torch.arange(len(vocab))\n",
    "\n",
    "# 每个柱子的宽度\n",
    "bar_width = 0.15\n",
    "\n",
    "# 创建图形和坐标轴\n",
    "# figsize=(5,3) 表示图形宽 5 英寸，高 3 英寸\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "# 循环绘制不同温度下的柱状图\n",
    "for i, T in enumerate(temperatures):\n",
    "    # x + i*bar_width：为了不同温度的柱子不重叠，横向偏移 i*bar_width\n",
    "    # scaled_probas[i]：该温度下每个 token 的概率\n",
    "    # bar_width：柱子宽度\n",
    "    # label=f'Temperature = {T}'：图例标签\n",
    "    rects = ax.bar(\n",
    "        x + i * bar_width, \n",
    "        scaled_probas[i], \n",
    "        bar_width, \n",
    "        label=f'Temperature = {T}'\n",
    "    )\n",
    "\n",
    "# 设置 y 轴标签\n",
    "ax.set_ylabel('Probability')\n",
    "\n",
    "# 设置 x 轴刻度位置\n",
    "ax.set_xticks(x)\n",
    "\n",
    "# 设置 x 轴刻度标签\n",
    "# vocab.keys() 是 token 名称\n",
    "# rotation=90 表示旋转 90 度，使标签竖直显示，避免重叠\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "\n",
    "# 显示图例\n",
    "ax.legend()\n",
    "\n",
    "# 调整布局，避免标签或图例被裁剪\n",
    "plt.tight_layout()\n",
    "\n",
    "# 保存图形为 PDF\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750e989-842a-4cfa-a44b-cf44d6e49163",
   "metadata": {},
   "source": [
    "- 我们可以看到，通过温度参数 0.1 进行重新缩放（rescaling）会得到一个更尖锐的分布，接近于 `torch.argmax`，这样最可能的单词几乎总是被选中：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4600713-c51e-4f53-bf58-040a6eb362b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "985 x forward\n",
      "0 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "15 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "# 调用我们之前定义的函数 print_sampled_tokens\n",
    "# 作用：根据概率向量采样 1000 次 token，并统计每个 token 被采样的次数\n",
    "# scaled_probas[1] 是温度 T=0.1 对应的概率分布\n",
    "print_sampled_tokens(scaled_probas[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526e93cb-8e2a-42a1-b1ba-4fd5fe64c26b",
   "metadata": {},
   "source": [
    "- 通过温度参数 5 进行重新缩放后的概率分布更接近均匀分布：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9dfb48f0-bc3f-46a5-9844-33b6c9b0f4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 x closer\n",
      "75 x every\n",
      "42 x effort\n",
      "239 x forward\n",
      "71 x inches\n",
      "46 x moves\n",
      "32 x pizza\n",
      "227 x toward\n",
      "103 x you\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c83f0c4-3774-4375-ad7f-96440ba5fef7",
   "metadata": {},
   "source": [
    "- 假设 LLM 的输入为 \"every effort moves you\"，使用上述采样方法有时会生成无意义的文本，例如 \"every effort moves you pizza\"，出现概率为 3.2%（在 1,000 次中出现 32 次）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e4873e-07e4-4abb-85df-bdaedcc1a6f7",
   "metadata": {},
   "source": [
    "### 5.3.2 Top-k 采样\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4da95a-8bb2-4f69-a9b0-a643531db5df",
   "metadata": {},
   "source": [
    "- 为了能够使用更高的温度（temperature）来增加输出的多样性，并降低生成无意义句子的概率，我们可以将采样范围限制在概率最高的前 k 个 token（top-k tokens）：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6fffd-2730-4abe-a2d3-781fc4836f17",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/15.webp\" width=500px>\n",
    "\n",
    "- （请注意，为了减少视觉混乱，图中的数字仅保留了小数点后两位。Softmax 行中的数值总和应为 1.0。）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba12da5-6ff1-4008-91b8-d2d537cbc14c",
   "metadata": {},
   "source": [
    "- 在代码中，我们可以如下实现 Top-k 采样：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a7f908a-e9ec-446a-b407-fb6dbf05c806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "# 设置 top-k 采样参数\n",
    "top_k = 3  # 我们只考虑概率最大的前 3 个 token\n",
    "\n",
    "# torch.topk 函数：返回张量中前 k 个最大值及其索引\n",
    "# 参数解释：\n",
    "#   next_token_logits : 输入张量（本例中是 logits，长度 = 词汇表大小）\n",
    "#   top_k             : 返回前 k 个元素\n",
    "# 返回：\n",
    "#   top_logits : 前 k 个最大值（tensor）\n",
    "#   top_pos    : 对应的索引（tensor），即 token id\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "# 打印前 k 个最大 logits 的值\n",
    "print(\"Top logits:\", top_logits)\n",
    "\n",
    "# 打印前 k 个最大 logits 对应的 token id\n",
    "print(\"Top positions:\", top_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "753865ed-79c5-48b1-b9f2-ccb132ff1d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "# 目标：实现 Top-K 采样的 logits 屏蔽\n",
    "# 将非 top-k 的 logits 设置为 -inf，从而在 softmax 时概率为 0\n",
    "\n",
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],  # 条件：哪些 logits 小于 top-k 中最小的那个\n",
    "    input=torch.tensor(float(\"-inf\")),            # 满足条件的元素替换为 -inf\n",
    "    other=next_token_logits                        # 不满足条件的元素保持原值\n",
    ")\n",
    "\n",
    "# 输出处理后的 logits\n",
    "print(new_logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa6fa49-6e99-459d-a517-d7d0f51c4f00",
   "metadata": {},
   "source": [
    "> 注意：  \n",
    ">\n",
    "> 上一个代码单元格的另一种稍微高效的实现如下：\n",
    ">\n",
    "> ```python\n",
    "> new_logits = torch.full_like( # 创建一个所有元素为 -inf 的张量\n",
    ">    next_token_logits, -torch.inf\n",
    ">)   \n",
    "> new_logits[top_pos] = next_token_logits[top_pos] # 将 top k 的值复制到 -inf 张量中\n",
    "> ```\n",
    "> <br>\n",
    "> 更多细节请参见 https://github.com/rasbt/LLMs-from-scratch/discussions/326\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4844f000-c329-4e7e-aa89-16a2c4ebee43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "# 将处理后的 logits 转换为概率分布\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56056503-a15d-4315-a3ff-46647a4c7c45",
   "metadata": {},
   "source": [
    "### 5.3.3 修改文本生成函数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34770423-473d-46f6-a5fa-6b2979564d26",
   "metadata": {},
   "source": [
    "- 前面两个小节介绍了温度采样（temperature sampling）和 Top-k 采样（top-k sampling）。  \n",
    "- 现在让我们使用这两个概念来修改第 4 章的 `generate_text_simple` 函数，创建一个新的 `generate` 函数：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e318891-bcc0-4d71-b147-33ce55febfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    \"\"\"\n",
    "    基于当前上下文 idx 生成新的 token 序列\n",
    "\n",
    "    参数：\n",
    "    - model: 已训练的 GPT 模型\n",
    "    - idx: 当前上下文 token 索引张量，形状 [batch_size, n_tokens]\n",
    "    - max_new_tokens: 最多生成的新 token 个数\n",
    "    - context_size: 模型最大上下文长度\n",
    "    - temperature: 温度系数，控制采样分布的平滑度（0 表示贪心）\n",
    "    - top_k: 如果不为 None，则进行 top-k 采样\n",
    "    - eos_id: 如果不为 None，遇到该 token 将提前停止生成\n",
    "    \"\"\"\n",
    "\n",
    "    # 生成循环，每次生成一个新的 token\n",
    "    for _ in range(max_new_tokens):\n",
    "        # -------------------------\n",
    "        # 截断上下文以适应模型最大 context_size\n",
    "        # idx_cond 形状: [batch_size, min(current_seq_len, context_size)]\n",
    "        # -------------------------\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        # -------------------------\n",
    "        # 前向推理，禁用梯度\n",
    "        # -------------------------\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)  # 输出形状: [batch_size, seq_len, vocab_size]\n",
    "\n",
    "        # 只关注最后一个 token 的 logits，形状: [batch_size, vocab_size]\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # -------------------------\n",
    "        # top-k 采样逻辑\n",
    "        # -------------------------\n",
    "        if top_k is not None:\n",
    "            # 获取每行前 top_k 个 logits 及其索引\n",
    "            top_logits, _ = torch.topk(logits, top_k)  # top_logits 形状: [batch_size, top_k]\n",
    "\n",
    "            # 最小的 top-k 值（第 k 大）\n",
    "            min_val = top_logits[:, -1].unsqueeze(-1)  # 形状: [batch_size, 1]，用于广播\n",
    "\n",
    "            # 将小于 top-k 最小值的 logits 设置为 -inf\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float(\"-inf\")).to(logits.device),  # 置为 -inf\n",
    "                logits\n",
    "            )\n",
    "\n",
    "        # -------------------------\n",
    "        # 温度缩放逻辑\n",
    "        # -------------------------\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature  # logits 除以温度，T>1 平滑分布，T<1 使分布更尖锐\n",
    "\n",
    "            # 数值稳定性优化（特别是 MPS 或 GPU 上）\n",
    "            logits = logits - logits.max(dim=-1, keepdim=True).values  # 减去行最大值\n",
    "\n",
    "            # softmax 转换为概率分布\n",
    "            probs = torch.softmax(logits, dim=-1)  # [batch_size, vocab_size]\n",
    "\n",
    "            # 按概率采样下一个 token\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # [batch_size, 1]\n",
    "\n",
    "        # -------------------------\n",
    "        # temperature=0 时使用贪心策略\n",
    "        # -------------------------\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # [batch_size, 1]\n",
    "\n",
    "        # -------------------------\n",
    "        # 遇到 eos_id 时提前停止生成\n",
    "        # -------------------------\n",
    "        if eos_id is not None and (idx_next == eos_id).all():\n",
    "            break\n",
    "\n",
    "        # -------------------------\n",
    "        # 将生成的 token 添加到当前序列\n",
    "        # idx 形状: [batch_size, n_tokens+1]\n",
    "        # -------------------------\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa2a0d7d-0457-42d1-ab9d-bd67683e7ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you stand to work on surprise, a one of us had gone with random-\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 设置随机种子，保证采样可复现\n",
    "# -------------------------\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# -------------------------\n",
    "# 调用自定义的 generate 函数生成新 token 序列\n",
    "# -------------------------\n",
    "token_ids = generate(\n",
    "    model=model,  # 已训练的 GPT 模型\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(inference_device),  \n",
    "    # 初始上下文，将文本编码为 token，并移动到指定设备（CPU/GPU）\n",
    "\n",
    "    max_new_tokens=15,  \n",
    "    # 最多生成 15 个新的 token\n",
    "\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],  \n",
    "    # 模型的最大上下文长度，用于截断输入序列\n",
    "\n",
    "    top_k=25,  \n",
    "    # 仅从概率最高的前 25 个 token 中采样，控制生成多样性\n",
    "\n",
    "    temperature=1.4  \n",
    "    # 温度系数 T>1 会让分布更平滑，提高随机性\n",
    "    # T<1 会让分布更尖锐，更倾向选择高概率 token\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 将生成的 token 序列解码为可读文本\n",
    "# -------------------------\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2002ca-f4c1-48af-9e0a-88bfc163ba0b",
   "metadata": {},
   "source": [
    "## 5.4 在 PyTorch 中加载和保存模型权重\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc52676-f026-4566-a226-2a90269f9d53",
   "metadata": {},
   "source": [
    "- 训练 LLM 的计算成本很高，因此能够保存和加载 LLM 权重非常重要。\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/16.webp\" width=400px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e4c7f9-592f-43d6-a00e-598fa01dfb82",
   "metadata": {},
   "source": [
    "- 在 PyTorch 中，推荐的做法是保存模型权重，即所谓的 `state_dict`，方法是对模型的 `.state_dict()` 使用 `torch.save` 函数：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d67d869-ac04-4382-bcfb-c96d1ca80d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 保存模型参数到本地文件\n",
    "# -------------------------\n",
    "torch.save(\n",
    "    model.state_dict(),  # 获取模型的所有可训练参数（权重和偏置）\n",
    "    \"model.pth\"           # 保存文件名，可自定义，如 \"gpt_model.pth\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e889e0-07bf-43e5-8f92-5c5c7aeaad9e",
   "metadata": {},
   "source": [
    "- 然后，我们可以将模型权重加载到一个新的 `GPTModel` 实例中，如下所示：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d57d914-60a3-47f1-b499-5352f4c457cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 1️ 重新创建模型结构\n",
    "# -------------------------\n",
    "model = GPTModel(GPT_CONFIG_124M)  \n",
    "# 这里必须先用和训练时完全相同的配置创建模型对象\n",
    "# GPT_CONFIG_124M 包含 vocab_size、emb_dim、n_layers、n_heads 等参数\n",
    "\n",
    "# -------------------------\n",
    "# 2️ 选择设备\n",
    "# -------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n",
    "# 优先使用 GPU，如果没有 GPU 则使用 CPU\n",
    "\n",
    "# -------------------------\n",
    "# 3️ 加载模型权重\n",
    "# -------------------------\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"model.pth\",          # 保存的模型权重文件\n",
    "        map_location=device    # 将权重映射到当前设备（CPU 或 GPU）\n",
    "    ),\n",
    "#    weights_only=True         # 只加载权重，不改变模型结构\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 4️ 切换到评估模式\n",
    "# -------------------------\n",
    "model.eval()  \n",
    "# 禁用 Dropout / BatchNorm 等训练特定行为\n",
    "# 用于推理 / 生成文本\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa81aec-9c72-4f46-8ae2-4a4fde3edbc1",
   "metadata": {},
   "source": [
    "- 训练 LLM 时，通常会使用自适应优化器（adaptive optimizers），如 Adam 或 AdamW，而不是普通的 SGD。  \n",
    "- 这些自适应优化器会为每个模型权重存储额外的参数，因此如果我们计划后续继续预训练（pretraining），保存这些参数也是有意义的：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbd175bb-edf4-450e-a6de-d3e8913c6532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 保存模型权重和优化器状态\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "torch.save({\n",
    "    # 保存模型的参数字典\n",
    "    \"model_state_dict\": model.state_dict(),  \n",
    "    \n",
    "    # 保存优化器的参数字典（例如 AdamW 的动量、步数等状态）\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),  \n",
    "}, \n",
    "\"model_and_optimizer.pth\")  # 保存为文件名 model_and_optimizer.pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a0c7295-c822-43bf-9286-c45abc542868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "# model = GPTModel(GPT_CONFIG_124M)\n",
    "# model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "# optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "# model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f802b6cd-b10d-4ace-983b-5c02764ad724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 1️ 加载 checkpoint 文件\n",
    "# -------------------------\n",
    "# checkpoint 文件包含模型权重和优化器状态字典\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=\"cpu\")\n",
    "# map_location=\"cpu\" 可以确保在 CPU 上加载，如果有 GPU 可以改为 map_location=device\n",
    "\n",
    "# -------------------------\n",
    "# 2️ 初始化模型\n",
    "# -------------------------\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "# -------------------------\n",
    "# 3️ 加载模型权重\n",
    "# -------------------------\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])  \n",
    "# 注意：这里不需要 weights_only=True，PyTorch 并不支持该参数\n",
    "\n",
    "# -------------------------\n",
    "# 4️ 初始化优化器\n",
    "# -------------------------\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "\n",
    "# -------------------------\n",
    "# 5️ 加载优化器状态\n",
    "# -------------------------\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "# -------------------------\n",
    "# 6️ 切换到训练模式\n",
    "# -------------------------\n",
    "model.train()  # 如果用于推理则用 model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4194350e-0409-4a63-8ffd-d3a896509032",
   "metadata": {},
   "source": [
    "## 5.5 从 OpenAI 加载预训练权重\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb6c38-7278-40e0-bd9f-8a2b1feac3ec",
   "metadata": {},
   "source": [
    "- 之前，我们仅使用一个非常短的小故事书对一个小型 GPT-2 模型进行了训练，主要出于教学目的。  \n",
    "- 感兴趣的读者也可以在 [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg) 找到在完整 Project Gutenberg 书籍语料库上进行的更长时间的预训练示例。  \n",
    "- 幸运的是，我们不必花费数万甚至数十万美元在大型预训练语料上训练模型，而可以直接加载 OpenAI 提供的预训练权重。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127ddbdb-3878-4669-9a39-d231fbdfb834",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "⚠️ **注意：在本节中，一些用户可能会遇到 TensorFlow 兼容性问题，尤其是在某些 Windows 系统上。这里使用 TensorFlow 仅用于加载原始的 OpenAI GPT-2 权重文件，然后将其转换为 PyTorch。  \n",
    "如果你遇到与 TensorFlow 相关的问题，可以使用下面的替代代码，而不是本节余下的代码。  \n",
    "该替代方案基于预先转换好的 PyTorch 权重，转换过程与前一节中描述的相同。详情请参阅笔记本：[../02_alternative_weight_loading/weight-loading-pytorch.ipynb](../02_alternative_weight_loading/weight-loading-pytorch.ipynb)。**\n",
    "\n",
    "\n",
    "```python\n",
    "file_name = \"gpt2-small-124M.pth\"\n",
    "# file_name = \"gpt2-medium-355M.pth\"\n",
    "# file_name = \"gpt2-large-774M.pth\"\n",
    "# file_name = \"gpt2-xl-1558M.pth\"\n",
    "\n",
    "url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    print(f\"Downloaded to {file_name}\")\n",
    "\n",
    "gpt = GPTModel(BASE_CONFIG)\n",
    "gpt.load_state_dict(torch.load(file_name, weights_only=True))\n",
    "gpt.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpt.to(device);\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cab892-a165-4f43-9601-f517bc212ab6",
   "metadata": {},
   "source": [
    "- 首先，一些样板代码用于从 OpenAI 下载文件并将权重加载到 Python 中。  \n",
    "- 由于 OpenAI 使用了 [TensorFlow](https://www.tensorflow.org/)，我们需要安装并使用 TensorFlow 来加载权重；[tqdm](https://github.com/tqdm/tqdm) 是一个进度条库。  \n",
    "- 取消注释并运行下一个单元格，以安装所需的库。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb9fdf02-972a-444e-bf65-8ffcaaf30ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0747edc-559c-44ef-a93f-079d60227e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "tqdm version: 4.67.1\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version:\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5bc89eb-4d39-4287-9b0c-e459ebe7f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 1️ 从本地模块导入函数\n",
    "# -------------------------\n",
    "# 相对导入 gpt_download.py 文件中的 download_and_load_gpt2 函数\n",
    "# 假设 gpt_download.py 与当前 Notebook/脚本在同一目录\n",
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "# -------------------------\n",
    "# 2️ 可选的替代导入方式\n",
    "# -------------------------\n",
    "# 如果你安装了 llms-from-scratch 包，可以直接从包中导入\n",
    "# 注意：包名可能随版本不同而不同，路径要根据实际安装情况修改\n",
    "# from llms_from_scratch.ch05 import download_and_load_gpt2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76a736-6f9f-4328-872e-f89a7b70a2cc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**注意**\n",
    "\n",
    "- 在极少数情况下，上面的代码单元可能会导致 `zsh: illegal hardware instruction python` 错误，这可能是由于你机器上的 TensorFlow 安装问题。  \n",
    "- 有读者发现，在这种情况下，通过 `conda` 安装 TensorFlow 可以解决问题，如 [这里](https://github.com/rasbt/LLMs-from-scratch/discussions/273#discussioncomment-12367888) 所述。  \n",
    "- 你可以在这个补充的 [Python 安装教程](https://github.com/rasbt/LLMs-from-scratch/tree/main/setup/01_optional-python-setup-preferences#option-2-using-conda) 中找到更多说明。\n",
    "\n",
    "---\n",
    "\n",
    "- 然后，我们可以按如下方式下载 1.24 亿参数模型的权重：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76271dd7-108d-4f5b-9c01-6ae0aac4b395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████████████████████████████████████████████████████████████| 77.0/77.0 [00:00<00:00, 39.7kiB/s]\n",
      "encoder.json: 100%|██████████████████████████████████████████████████████████████| 1.04M/1.04M [00:00<00:00, 1.25MiB/s]\n",
      "hparams.json: 100%|████████████████████████████████████████████████████████████████| 90.0/90.0 [00:00<00:00, 51.0kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████████████████████████████████████████| 498M/498M [03:36<00:00, 2.30MiB/s]\n",
      "model.ckpt.index: 100%|██████████████████████████████████████████████████████████| 5.21k/5.21k [00:00<00:00, 5.24MiB/s]\n",
      "model.ckpt.meta: 100%|██████████████████████████████████████████████████████████████| 471k/471k [00:00<00:00, 810kiB/s]\n",
      "vocab.bpe: 100%|████████████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 766kiB/s]\n"
     ]
    }
   ],
   "source": [
    "# 调用 download_and_load_gpt2 函数下载并加载 GPT-2 模型权重\n",
    "# 并返回两个对象：模型配置（settings）和模型参数（params）\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\",   # 指定 GPT-2 模型大小，可选 \"124M\", \"355M\", \"774M\", \"1558M\"\n",
    "    models_dir=\"gpt2\"    # 指定本地存储预训练模型权重的目录，如果不存在则会自动创建\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 返回值说明：\n",
    "# -------------------------\n",
    "# settings: 包含模型架构信息（如层数、头数、embedding 维度等）的字典\n",
    "# params:   一个字典，包含所有下载的模型权重（如 token embedding、attention 权重等）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1a31951-d971-4a6e-9c43-11ee1168ec6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "# 打印 GPT-2 模型的配置信息\n",
    "# settings 是一个字典，包含模型的架构参数和超参数\n",
    "print(\"Settings:\", settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "857c8331-130e-46ba-921d-fa35d7a73cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "# 打印从 GPT-2 下载的权重字典的键\n",
    "# params 是一个字典（Python dict），存储模型的所有参数张量\n",
    "# keys() 方法返回字典中所有键名，方便了解模型有哪些参数\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c48dac94-8562-4a66-84ef-46c613cdc4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 查看 GPT-2 模型的 token embedding 权重\n",
    "# -----------------------------\n",
    "\n",
    "# 打印 \"wte\" 对应的张量\n",
    "# 'wte' 是 \"word token embedding\" 的简称\n",
    "# 即词表中每个 token 对应的嵌入向量 (embedding vector)\n",
    "print(params[\"wte\"])\n",
    "\n",
    "# 打印 token embedding 张量的形状（维度）\n",
    "# 通常形状为 [vocab_size, emb_dim]\n",
    "# vocab_size：词表大小，即有多少不同的 token\n",
    "# emb_dim：嵌入向量的维度（GPT-2 小模型 124M 为 768）\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466e100c-294e-4afc-a70a-2f398ac4c104",
   "metadata": {},
   "source": [
    "- 另外，`model_size` 参数还支持 \"355M\"、\"774M\" 和 \"1558M\"。  \n",
    "- 不同大小模型的差异总结如下图：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f19d32-5aae-4176-9f86-f391672c8f0d",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/17.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e5076-f08d-41fc-bd8b-1cfe53538f41",
   "metadata": {},
   "source": [
    "- 上面，我们已经将 1.24 亿参数的 GPT-2 模型权重加载到 Python 中，但我们仍需要将它们转移到我们的 `GPTModel` 实例中。  \n",
    "- 首先，我们初始化一个新的 `GPTModel` 实例。  \n",
    "- 注意，原始 GPT 模型在多头注意力模块中初始化查询（query）、键（key）和值（value）矩阵的线性层时使用了偏置向量（bias vectors），这并非必须或推荐；但为了能够正确加载权重，我们在实现中也必须将 `qkv_bias` 设置为 `True`。  \n",
    "- 我们还使用了原始 GPT-2 模型采用的 `1024` token 上下文长度（context length）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9fef90dd-0654-4667-844f-08e28339ef7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1️ 定义不同 GPT-2 模型的基础配置字典\n",
    "# -----------------------------\n",
    "# 每个 key 是模型名称，value 是一个字典，包含该模型的核心参数：\n",
    "# - emb_dim: 词向量维度\n",
    "# - n_layers: Transformer 层数\n",
    "# - n_heads: 多头注意力头数\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 2️ 选择要使用的模型名称\n",
    "# -----------------------------\n",
    "model_name = \"gpt2-small (124M)\"  # 示例：使用最小的 124M GPT-2\n",
    "\n",
    "# -----------------------------\n",
    "# 3️ 复制基础配置并更新为选定模型的参数\n",
    "# -----------------------------\n",
    "# GPT_CONFIG_124M 是之前定义的基础配置字典\n",
    "# 使用 copy() 避免修改原始字典\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "\n",
    "# 更新为指定模型的核心参数（词向量维度、层数、多头数）\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "\n",
    "# 进一步更新上下文长度和 QKV bias（可选）\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "# -----------------------------\n",
    "# 4️ 初始化 GPT 模型\n",
    "# -----------------------------\n",
    "# 使用更新后的配置创建 GPTModel 实例\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "\n",
    "# -----------------------------\n",
    "# 5️ 切换模型到评估模式\n",
    "# -----------------------------\n",
    "# eval() 禁用 dropout 和其他训练时特性，用于推理\n",
    "gpt.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272f29ac-8342-4b3d-a57d-9b0166ced314",
   "metadata": {},
   "source": [
    "- 接下来的任务是将 OpenAI 权重分配给我们 `GPTModel` 实例中的对应权重张量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9a92229-c002-49a6-8cfb-248297ad8296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    \"\"\"\n",
    "    将右侧张量的值赋给左侧张量，并返回一个 nn.Parameter 类型的张量。\n",
    "    主要用于确保在模型权重初始化或更新时，左右张量形状匹配。\n",
    "\n",
    "    参数：\n",
    "    - left: 原始张量（通常是模型的权重张量）\n",
    "    - right: 新的张量（通常来自外部权重或预训练权重）\n",
    "\n",
    "    返回：\n",
    "    - 一个 torch.nn.Parameter 类型的张量，值与 right 相同\n",
    "    \"\"\"\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 1️ 检查左右张量的形状是否一致\n",
    "    # -----------------------------\n",
    "    # 如果形状不匹配，抛出错误，避免赋值错误\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 2️ 创建一个新的 nn.Parameter\n",
    "    # -----------------------------\n",
    "    # torch.tensor(right) 将 right 转换为新的张量\n",
    "    # nn.Parameter 会将其注册为模型的可训练参数\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f22d5d95-ca5a-425c-a9ec-fc432a12d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    \"\"\"\n",
    "    将下载的 GPT-2 预训练权重加载到自定义 GPT 模型中。\n",
    "    \n",
    "    参数：\n",
    "    - gpt: 自定义 GPTModel 实例\n",
    "    - params: 预训练模型权重字典，从 download_and_load_gpt2() 获取\n",
    "    \n",
    "    说明：\n",
    "    GPT-2 模型权重结构：\n",
    "    - 'wte' : token embedding 权重\n",
    "    - 'wpe' : position embedding 权重\n",
    "    - 'blocks' : 包含每个 Transformer Block 的字典列表\n",
    "    - 'g', 'b' : 最终 LayerNorm 的 scale 和 shift\n",
    "    \"\"\"\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 1️ 位置嵌入层 (Positional Embedding)\n",
    "    # -----------------------------\n",
    "    # GPT-2 使用固定长度 context 的位置编码，存储在 'wpe' 中\n",
    "    # gpt.pos_emb.weight 是自定义模型的位置嵌入层权重\n",
    "    # assign() 会检查形状并转换为 nn.Parameter\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 2️ 词嵌入层 (Token Embedding)\n",
    "    # -----------------------------\n",
    "    # gpt.tok_emb.weight 是自定义模型的词嵌入层权重\n",
    "    # 'wte' 来自 GPT-2 预训练模型\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 3️ Transformer Block 权重\n",
    "    # -----------------------------\n",
    "    # GPT-2 每一层 Transformer block 的权重存储在 blocks 列表中\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        \n",
    "        # -----------------------------\n",
    "        # 3.1 拆分 Q/K/V 权重\n",
    "        # -----------------------------\n",
    "        # GPT-2 的注意力层使用一个线性层 c_attn 同时生成 Q/K/V\n",
    "        # 权重 shape: (emb_dim, 3 * emb_dim)\n",
    "        # np.split 按最后一维分为三个矩阵\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1\n",
    "        )\n",
    "        \n",
    "        # PyTorch 的 nn.Linear 权重 shape: (out_features, in_features)\n",
    "        # 因此需要转置 q_w.T\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T\n",
    "        )\n",
    "        \n",
    "        # -----------------------------\n",
    "        # 3.2 拆分 Q/K/V 偏置\n",
    "        # -----------------------------\n",
    "        # 偏置 shape: (3*emb_dim,)\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b\n",
    "        )\n",
    "        \n",
    "        # -----------------------------\n",
    "        # 3.3 注意力输出投影 (Output Projection)\n",
    "        # -----------------------------\n",
    "        # c_proj 是注意力输出投影矩阵\n",
    "        # 转置原因同上\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"]\n",
    "        )\n",
    "        \n",
    "        # -----------------------------\n",
    "        # 3.4 前馈网络 (MLP)\n",
    "        # -----------------------------\n",
    "        # MLP 第一层 (c_fc)\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"]\n",
    "        )\n",
    "        # MLP 第二层 (c_proj)\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"]\n",
    "        )\n",
    "        \n",
    "        # -----------------------------\n",
    "        # 3.5 LayerNorm 权重\n",
    "        # -----------------------------\n",
    "        # norm1 对应注意力输出后的归一化\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"]\n",
    "        )\n",
    "        # norm2 对应 MLP 输出后的归一化\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"]\n",
    "        )\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 4️ 最终 LayerNorm 权重\n",
    "    # -----------------------------\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    \n",
    "    # -----------------------------\n",
    "    # 5️ 输出头权重 (weight tying)\n",
    "    # -----------------------------\n",
    "    # 输出头与词嵌入共享权重\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7472cb-54dc-4311-96d8-b2694f885cee",
   "metadata": {},
   "source": [
    "- 如果模型加载正确，我们可以使用之前的 `generate` 函数生成新文本：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f690253-f845-4347-b7b6-43fabbd2affa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward finding an ideal new way to practice something!\n",
      "\n",
      "What makes us want to be on top of that?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 设置随机种子以确保可复现的结果\n",
    "# ===============================\n",
    "torch.manual_seed(123)\n",
    "# 解释：\n",
    "# PyTorch 的随机种子影响所有随机操作（如 dropout、权重初始化、torch.multinomial 等）\n",
    "# 使用固定种子可以保证每次运行得到相同的生成序列，便于教学和实验对比\n",
    "\n",
    "# ===============================\n",
    "# 调用自定义生成函数生成文本\n",
    "# ===============================\n",
    "token_ids = generate(\n",
    "    model=gpt,  # 使用已加载权重的 GPT 模型\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),  \n",
    "    # 将初始文本 \"Every effort moves you\" 编码为 token id 张量，并移动到当前设备（CPU 或 GPU）\n",
    "    # text_to_token_ids 返回张量 shape [1, n_tokens]，其中 1 表示 batch size\n",
    "    \n",
    "    max_new_tokens=25,  \n",
    "    # 生成的新 token 数量\n",
    "    # 意味着在原始上下文的基础上，最多会生成 25 个新的 token\n",
    "    \n",
    "    context_size=NEW_CONFIG[\"context_length\"],  \n",
    "    # GPT 模型能够处理的最大上下文长度\n",
    "    # 超过此长度时会裁剪，只保留最近的 context_size 个 token\n",
    "    # 对应 Transformer 的自注意力窗口\n",
    "    \n",
    "    top_k=50,  \n",
    "    # Top-k 采样参数\n",
    "    # 生成每个 token 时，只从概率最高的 50 个 token 中采样\n",
    "    # 控制生成的多样性，避免低概率 token 干扰生成结果\n",
    "    \n",
    "    temperature=1.5  \n",
    "    # 温度参数，用于控制生成的随机性\n",
    "    # temperature > 1 → 分布更平坦 → 增加随机性，多样化生成\n",
    "    # temperature < 1 → 分布更陡 → 更倾向高概率 token，生成更确定\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 将生成的 token 序列解码为可读文本\n",
    "# ===============================\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "# token_ids_to_text(token_ids, tokenizer) 做了以下操作：\n",
    "# 1️ 将 token_ids 张量 squeeze(0)，去掉 batch 维度\n",
    "# 2️ 将张量转换为列表\n",
    "# 3️ 调用 tokenizer.decode 将 token id 列表映射回原始文本\n",
    "# 输出即为模型生成的连续文本\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d079f98-a7c4-462e-8416-5a64f670861c",
   "metadata": {},
   "source": [
    "- 我们之所以知道权重已经正确加载，是因为模型能够生成连贯的文本；如果哪怕有一点错误，模型就无法做到这一点。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28493b9b-a1ae-4f31-87bc-c10ee4447f44",
   "metadata": {},
   "source": [
    "- 关于从 Hugging Face Hub 加载权重的替代方法，请参见 [../02_alternative_weight_loading](../02_alternative_weight_loading)。  \n",
    "- 如果你想了解 GPT 架构与 Llama 架构（由 Meta AI 开发的流行 LLM）的对比，请参见附加内容 [../07_gpt_to_llama](../07_gpt_to_llama)。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a66474-230d-4180-a8ff-843e04f1f1c4",
   "metadata": {},
   "source": [
    "## 总结与要点\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7ed189-a633-458c-bf12-4f70b42684b8",
   "metadata": {},
   "source": [
    "- 请参见 [./gpt_train.py](./gpt_train.py) 脚本，这是一个用于训练的独立脚本  \n",
    "- [./gpt_generate.py](./gpt_generate.py) 脚本加载来自 OpenAI 的预训练权重，并根据提示生成文本  \n",
    "- 练习答案可以在 [./exercise-solutions.ipynb](./exercise-solutions.ipynb) 中找到\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
